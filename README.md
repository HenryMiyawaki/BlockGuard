# DetecÃ§Ã£o de Ataques em Blockchain com Aprendizado de MÃ¡quina

Status: âœ… Completo

![](https://img.shields.io/badge/Code-Python-informational?style=for-the-badge&logo=python&logoColor=white&color=BD2A95)

## 1ï¸âƒ£ IntroduÃ§Ã£o

As redes e sistemas descentralizados como blockchain, tÃªm ganhado destaque como uma alternativa eficiente e inovadora em um mundo cada vez mais preocupado com privacidade e autonomia ao se destacarem por: 

> - Eliminar a dependÃªncia de uma entidade central
> - Colaboratividade e Escalabilidade da rede
> - SeguranÃ§a e Imutabilidade

## 2ï¸âƒ£ Objetivos

Propomos, assim, um modelo que com os seguintes objetivos

> - âœ… Identifique tipos de ataques comuns em Blockchain.
>   - Brute Force
>   - Denial of Serivice (Dos)
>   - Flooding of Transactions
>   - Man-in-the-Middle
> - âœ… O modelo possa aprender com outros nÃ³s da rede.
> - âœ… Aprendizado descentralizada sem expor os dados dos peers.

## 3ï¸âƒ£ Metodologia 

Foi delimitado nossa problematica como um problema de **ClassificaÃ§Ã£o** onde seria necessario a partir de variaveis independentes classificar uma certa requisiÃ§Ã£o em 4 categorias.

### ðŸ“ˆ Dataset

O dataset escolhido foi o BNaT Dataset (Blockchain Network Attack Traffic Dataset) uma base de dados coletados de nÃ³s **Ethereum** que contÃªm os ataques listados nos objetivos.

-> [ConheÃ§a o BNaT Dataset](https://paperswithcode.com/dataset/bnat)

### ðŸ’» Modelo

Para resolver o problema de classificaÃ§Ã£o foi escolhido criar um modelo de **Rede Neural** devido a quantidade de itens para serem classificados, flexibilidade que uma rede neural pode ofererecer.

> Foi utilizado as seguintes ferramentas para a criaÃ§Ã£o da rede: 
> - Python 3.12.4
> - Pytorch
> - Scikit-learn
> - Numpy
> - Pandas

### ðŸ“Š PrÃ©-processamento

> Para melhorar a qualidade e divisÃ£o dos dados, foi adotada as seguintes tÃ©cnicas: 
> - EstratificaÃ§Ã£o para a separaÃ§Ã£o dos conjuntos de treino e teste
> - **TransformaÃ§Ã£o** matrizes de mÃºtiplas dimensÃµes para **vectorized operation**
> - Carregamento dos dados em lotes (batches embaralhados de 32 amostras)

### ðŸ§  Rede Neural

A rede neural foi construida da seguinte forma:

#### **3.1 Topologia**
> - A primeira camada Ã© totalmente conectada (linear) transforma a entrada de dimensÃ£o N em uma sÃ¡ida de 128 NeurÃ´nios.
> - A segunda camada tambÃ©m totalmente conectada porÃ©m reduz de 128 neurÃ´nios para 64.
> - A terceira camada totalmente conectada reduz a dimensÃ£o de 64 para 32 neurÃ´nios.
> - Por fim, a camada de saÃ­da reduz os 32 neurÃ´nios para o nÃºmero de classes do problema de classificaÃ§Ã£o.

Todas as camadas seguem os seguintes passos:
> 1. Os dados passame pela camada linear
> 2. Sofrem uma normalizaÃ§Ã£o em lotes
> 3. Ã‰ aplicado a funÃ§Ã£o de ativaÃ§Ã£o ReLU (Rectified Linear Unit)

#### **3.2 FunÃ§Ã£o de Perda e Otimizador**
```diff
- Para calcular a perda da rede foi utilizado o Cross-Entropy-Loss. 
+ Para otimizar o modelo foi escolhido o Adaptive Moment Estimation (ADAM).
+ Scheduler foi usado para ajsutar dinamicamente a taxa de aprendizado.
- Caso 3 Ã©pocas consecutivas sem progresso Ã© aplicado um fator de 0.5 na taxa de aprendizado.
```
***

| ðŸ’¾ Taxa de aprendizado       | ðŸ“RegularizaÃ§Ã£o   |
| -----------                  | -----------        |
| 0.001                        | **L1 (Lasso)**     |


## 4ï¸âƒ£ Treinamento

> Para o processo de treinamento foi definido um mecanismo de **Early Stopping** que interrome o treinamento caso o demolo nÃ£o apresente melhorias consecutivas em um determiando nÃºmero de Ã©pocas.

Durante o processo de treino funcionalidades especificas sÃ¡o atividas usadas como **dropout** e **normalizaÃ§Ã£o**
1. -> Para cada iteraÃ§Ã£o moveremos os dados do batch para o dispositivo para a CPU ou GPU (CUDA)
2. -> Calcula-se a saÃ­da do modelo e a perda associada
3. -> Ã‰ **zerado** os gradientes acumulados
4. -> Utilizamos as perdas calculadas para calcular o gradiente dos parÃ¢metros do modelo.
5. -> Calculamos a perda do lote e a perda mÃ©doa da Ã©poca
6. -> Por fim Ã© verificado a condiÃ§Ã£o de **Early Stopping**

## 5ï¸âƒ£ Peer Network

## 6ï¸âƒ£ Vantagens do Peer Network

## 7ï¸âƒ£ Resultados

Os resultados obtidos podem ser observados nos seguintes grÃ¡ficos.

> ### ROC Curve
> <img src="/results/roc_curve.png" alt="DescriÃ§Ã£o da imagem" width="600">
> 
> ### Class Distribution
> <img src="/results/class_distribution.png" alt="DescriÃ§Ã£o da imagem" width="600">
> 
> ### Confusion Matrix
> <img src="/results/confusion_matrix.png" alt="DescriÃ§Ã£o da imagem" width="600">

# Contribuidores
- [Felipe Nunes Melo](https://github.com/felipemelonunes09)
- [Henry Miyawaki](https://github.com/HenryMiyawaki)
